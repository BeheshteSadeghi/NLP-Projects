{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import numpy as np\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "hCyKytucFKfo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bki77EYFNWk",
        "outputId": "364db485-c56c-4ef4-fe85-d4d7d12c1fb5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "V8GGnUKTFOGP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading text file - to summarize\n",
        "file = open(\"article.txt\",\"r\")"
      ],
      "metadata": {
        "id": "8Us83o_vJLa9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ''\n",
        "for line in file:\n",
        "  text += line.strip()+\" \""
      ],
      "metadata": {
        "id": "yXyTTYoZYiBc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text tokenization to words\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Creating a frequency table to keep the score of each word\n",
        "freqTable = dict()\n",
        "for word in words:\n",
        "\tword = word.lower()\n",
        "\tif word in stopWords:\n",
        "\t\tcontinue\n",
        "\tif word in freqTable:\n",
        "\t\tfreqTable[word] += 1\n",
        "\telse:\n",
        "\t\tfreqTable[word] = 1\n",
        "\n",
        "# Text tokenization to sentences\n",
        "sentences = sent_tokenize(text)\n",
        "sentenceValue = dict()\n",
        "\n",
        "# Creating a dictionary to keep the score of each sentence\n",
        "for sentence in sentences:\n",
        "\tfor word, freq in freqTable.items():\n",
        "\t\tif word in sentence.lower():\n",
        "\t\t\tif sentence in sentenceValue:\n",
        "\t\t\t\tsentenceValue[sentence] += freq\n",
        "\t\t\telse:\n",
        "\t\t\t\tsentenceValue[sentence] = freq\n",
        "\n",
        "\n",
        "# Assignigning value to sentences based on frequency of ezch sentences' words\n",
        "sumValues = 0\n",
        "for sentence in sentenceValue:\n",
        "\tsumValues += sentenceValue[sentence]\n",
        "\n",
        "# Average value of a sentence from the original text\n",
        "average = int(sumValues / len(sentenceValue))\n",
        "\n",
        "# Generating summary\n",
        "summary = ''\n",
        "for sentence in sentences:\n",
        "\t  if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
        "\t\t  summary += \"\\n \" + sentence\n",
        "\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAevoqR8FQ_s",
        "outputId": "c81a5f9f-c64e-4e01-a79b-f4dbb6ec3242"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Artificial intelligence for automatic classification of needle EMG signals:A scoping review This scoping review provides an overview of artificial intelligence (AI), including machine and deep learning techniques, in the interpretation of clinical needle electromyography (nEMG) signals.\n",
            " 61% used open-source EMGlab data set to develop models to classify nEMG signal in healthy, amyotrophic lateral sclerosis (ALS) and myopa\u0002thy (25 subjects).\n",
            " Significance: The outcomes of this study and the suggestions made aim to contribute to developing AI\u0002models that can effectively handle signal quality variability and are suitable for daily clinical practice in interpreting nEMG signals.\n"
          ]
        }
      ]
    }
  ]
}